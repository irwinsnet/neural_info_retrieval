
# root link for the paper on github (reference only)
https://github.com/AdeDZY/DeepCT

# set up the virtual python
apt-get install python3-venv
python3 -m venv venv_deepct/
source venv_deepct/bin/activate

# upgrade pip and get tensorflow
python -m pip install --upgrade pip setuptools
pip3 install --upgrade pip
pip3 install tensorflow==1.15.0
pip3 install tensorflow-gpu==1.15.0

# clone out the DeepCT repo for baseline
export BASELINE_HOME=/home/ubuntu/trainvol/baseline
mkdir -p $BASELINE_HOME
cd $BASELINE_HOME
git clone https://github.com/AdeDZY/DeepCT.git

# set environment variables that we will require
export BERT_BASE_DIR=$BASELINE_HOME/uncased_L-12_H-768_A-12
export TRAIN_DATA_FILE=./data/marco/myalltrain.relevant.docterm_recall
export OUTPUT_DIR=./output/marco/

# fetch the datasets and unpack them. In this step, only the alltrain is required
mkdir -p $BASELINE_HOME/DeepCT/data/marco
cd $BASELINE_HOME/DeepCT/data/marco
wget http://boston.lti.cs.cmu.edu/appendices/arXiv2019-DeepCT-Zhuyun-Dai/data/collection.tsv.1.zip
wget http://boston.lti.cs.cmu.edu/appendices/arXiv2019-DeepCT-Zhuyun-Dai/data/collection.tsv.2.zip
wget http://boston.lti.cs.cmu.edu/appendices/arXiv2019-DeepCT-Zhuyun-Dai/data/myalltrain.relevant.docterm_recall
for zipfile in `ls coll*.zip`; do unzip $zipfile; done
rm -Rf coll*.zip

# fetch bert, unpack, cleanup
mkdir -p $BERT_BASE_DIR
cd $BERT_BASE_DIR
wget https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip
unzip uncased_L-12_H-768_A-12.zip
rm uncased_L-12_H-768_A-12.zip

# get ready to run/test
cd $BASELINE_HOME/DeepCT
mkdir -p $OUTPUT_DIR

python3 run_deepct.py \
  --task_name=marcodoc \
  --do_train=true \
  --do_eval=false \
  --do_predict=false \
  --data_dir=$TRAIN_DATA_FILE \
  --vocab_file=$BERT_BASE_DIR/vocab.txt \
  --bert_config_file=$BERT_BASE_DIR/bert_config.json \
  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
  --max_seq_length=128 \
  --train_batch_size=16 \
  --learning_rate=2e-5 \
  --num_train_epochs=3.0 \
  --recall_field=title \
  --output_dir=$OUTPUT_DIR


## this next block is to predict weights
#

# set environment variables that we will require
export BASELINE_HOME=/home/ubuntu/trainvol/baseline
export BERT_BASE_DIR=$BASELINE_HOME/uncased_L-12_H-768_A-12
export INIT_CKPT=./output/marco/model.ckpt-0
export TEST_DATA_FILE=./data/marco/collection.tsv.1
export OUTPUT_DIR=./predictions/marco/collection_pred_1/

mkdir -p $OUTPUT_DIR

python run_deepct.py \
 --task_name=marcotsvdoc \
 --do_train=false \
 --do_eval=false \
 --do_predict=true \
 --data_dir=$TEST_DATA_FILE \
 --vocab_file=$BERT_BASE_DIR/vocab.txt \
 --bert_config_file=$BERT_BASE_DIR/bert_config.json \
 --init_checkpoint=$INIT_CKPT \
 --max_seq_length=128 \
 --train_batch_size=16 \
 --learning_rate=2e-5 \
 --num_train_epochs=3.0 \
 --output_dir=$OUTPUT_DIR

/dev/xvdf on /home/ubuntu/trainvol