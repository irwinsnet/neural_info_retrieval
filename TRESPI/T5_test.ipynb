{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ordered-municipality",
   "metadata": {},
   "source": [
    "# T5 Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unavailable-kitchen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2122c97-6fa7-44d2-9faa-eb6bf77ddf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.T5Tokenizer.from_pretrained(\n",
    "    'castorini/doc2query-t5-base-msmarco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "civil-greene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce1a3a24c22427a9ae8a00e1ac7f7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3bbbd16cf241a8bf1ce6e982823ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_fast = transformers.T5TokenizerFast.from_pretrained(\n",
    "    't5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "danish-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.T5ForConditionalGeneration.from_pretrained(\n",
    "    'castorini/doc2query-t5-base-msmarco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "promising-senegal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72361cb2-3257-4106-8eea-908121e59032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba36564e-7fcc-4d32-a46e-1779cccaabae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts model on GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0348af0b-e9a2-41e1-82b9-400368c29242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 1: what was the main purpose of the manhattan project?\n",
      "sample 2: why was the manhattan project such a important event\n",
      "sample 3: why did the manhattan project happen\n",
      "sample 4: what was the main achievement of the manhattan project?\n",
      "sample 5: why was the manhattan project so important?\n",
      "sample 6: why did the manhattan project happen\n",
      "sample 7: what was the most important achievement of the manhattan project?\n"
     ]
    }
   ],
   "source": [
    "num_outputs = 7\n",
    "doc_text = ('The presence of communication amid scientific minds was equally '\n",
    "            'important to the success of the Manhattan Project as scientific '\n",
    "            'intellect was. The only cloud hanging over the impressive '\n",
    "            'achievement of the atomic researchers and engineers is what '\n",
    "            'their success truly meant; hundreds of thousands of innocent '\n",
    "            'lives obliterated.')\n",
    "\n",
    "input_ids = tokenizer.encode(doc_text, return_tensors='pt').to(device)\n",
    "outputs = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=64,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=num_outputs)\n",
    "\n",
    "for i in range(num_outputs):\n",
    "    print(f'sample {i + 1}: {tokenizer.decode(outputs[i], skip_special_tokens=True)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57461f4f-8f8b-4cd9-9fc0-009f1e9f9c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
