# Calculating Term Predictions with DeepCT
This folder contains a bash script, `deepct_predict.sh`, that can be used to
generate DeepCT term predictions from multiple input files containing
MSMARCO text passages. We are using the the word *predictions* to refer
to the unscaled, passage-level weights generated by the DeepCT
prediction step, where the weights are typically within the range of
0.0 - 1.0.

DeepCT generates term predictions by submitting text passages to a fine-tuned
BERT model. This is an inference step that can be conducted in parallel on
multiple machines. The `deepct_predict.sh` script assumes that the input files
are all named passages_NNN.tsv where NNN is a file sequence number
starting at 000. The `deepct_predict.sh` script accepts a beginning and ending
file sequence number as parameters and processes only the files that
fall within that range.

Processing the entire MSMARCO document dataset on an AWS g4dn EC2
instance with one GPU required about 66 hours of processing time. We
were able to split the input data into four different batches of files
and process it in parallel on four different g4dn instances, which
reduced the prediction time to less than twenty hours.

Term weights will be written to corresponding files in the
predictions subfolder, i.e., psg_weights_nnn.tsv, where the integer
nnn corresponds to the integer index in the input file name.
The input file and corresponding output file have the same number of
lines.
   
Status messages are written to the predict.log file. The predict.log
file is saved in the folder from which deepct_predict.sh is run.

## Running `deepct_predict.sh`
### Python Environment Setup
DeepCT will automatically use a GPU if it detects a CUDA environment.
DeepCT requires Tensorflow 1.15. To run DeepCT, our team used an
AWS g4dn instance with an Ubuntu 18.04 Machine Learning AMI.

We first activated the built-in tensorflow2_latest_p37 environment to
Ensure CUDA was properly set up, then activated a Python virtual
environment with tensorflow version 1.15.0.

Assuming the virtual environment is in a folder named  `~/venv_deepct`,
the commands to activate the proper environment are:
1. `source activate tensorflow2_latest_p37` (sets up CUDA)
2. `source ~/venv_deepct/bin/activate` (Reverts to Tensorflow 1.15)

### Preparing Input Data
Use the `doc_split_deepCT/doc_to_psg.py` to generate input passages, either
from the original MSMARCO document dataset or from the query documents
created by the `create_query_docs/create_query_docs.py` script. Ensure
all input files are contained in a folder and are named `passages_NNN.tsv`,
where NNN is a file sequence number starting at 000.

### Create Output Folder
The `deepct_predict.sh` script will generate multiple output files.
Create an empty folder to contain these files.

### Prepare BERT and DeepCT Repositories.
1. Download the uncased_L-12_H-768_A-12 BERT model from the
[offical Google BERT repository](https://github.com/google-research/bert).
2. Clone the [DeepCT Github Repository](https://github.com/AdeDZY/DeepCT).
3. Follow instructions in the DeepCT Github README page to download model
data to the repository's *data* subfolder.

### Run DeepCT Prediction
deepct_predict.sh requires six positional arguments:
  1. Path to BERT model
  2. Path to DeepCT repository
  3. Path to input files
  4. Path to output folder
  5. file sequence number of first input file to be processed
  6. file sequence number of last input file to be processed.

  Example useage (assumes all resources are in user's home folder)
  ```bash
source deepct_predict.sh \
    ~/uncased_L-12_H-768_A-12 \
    ~/DeepCT \
    ~/msmarco-doc-passages \
    ~/predictions_output
    2
    5
```

The example command will run DeepCT predictions on four files:
    * passages_002.tsv
    * passages_003.tsv
    * passages_004.tsv
    * passages_005.tsv

The output files will be in folder `~/predictions_output`:
    * psg_weights_002.tsv
    * psg_weights_003.tsv
    * psg_weights_004.tsv
    * psg_weights_005.tsv